{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_DocumentExtraction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"C1wyoS0QNyIf","colab_type":"text"},"source":["**Initial the package and googledrive**"]},{"cell_type":"code","metadata":{"id":"ju95bCb6ba-5","colab_type":"code","colab":{}},"source":["#prepare google drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","!mkdir -p /content/gdrive/My\\ Drive/Colab\\ Notebooks/files/documents\n","%cd /content/gdrive/My\\ Drive/Colab\\ Notebooks\n","!pwd\n","\n","#HTML -> PDF\n","!apt-get update\n","!apt-get install wkhtmltopdf\n","!apt-get install xvfb\n","\n","#install additional fonts\n","!apt-get install fonts-thai-tlwg  #Thai fonts\n","!apt-get install fonts-takao-mincho  #Japanese fonts\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wCt9jZu_8uVD","colab_type":"text"},"source":["Download and convert Wikipedia page into PDF file."]},{"cell_type":"code","metadata":{"id":"9UcXmVgaWk25","colab_type":"code","colab":{}},"source":["from bs4 import BeautifulSoup\n","import urllib3\n","import csv\n","import os\n","\n","#========== Save Wikipedia page to PDF files ===========\n","\n","http = urllib3.PoolManager()\n","urllib3.disable_warnings()\n","\n","# #### get Keyword files ####\n","WikiKeywordURL = \"https://raw.githubusercontent.com/Eit-wc/Document-Clustering-/master/src/files/Wiki_Keywords.csv\"\n","WikiKeywordsFileName = \"./files/Wiki_Keywords.csv\"\n","os.system(f\"wget '{WikiKeywordURL}' -O '{WikiKeywordsFileName}'\")\n","\n","def savePDF(url,filename):\n","  print(f'save {url} -> {filename}')\n","  os.system(f\"xvfb-run wkhtmltopdf '{url}' ./files/documents/{filename}\")\n","\n","def getWikiPage(Keyword,Languages,label):\n","  global http\n","\n","  # Access english page\n","  url = f\"https://en.wikipedia.org/wiki/{Keyword}\"\n","  print(f'Request: {url}')\n","  enPage = http.request('GET', url)\n","\n","  if(enPage.status == 200):\n","\n","    # Download english page to PDF\n","    savePDF(url, f'{label}_{Keyword}_en.pdf')\n","\n","    # Find other languages\n","    soupEnPage = BeautifulSoup(enPage.data, 'html.parser')\n","    # loop other language\n","    for language in Languages:\n","      trageTag = soupEnPage.find_all('a',{'class' : 'interlanguage-link-target', 'lang':language})\n","      if(len(trageTag) >0):\n","\n","        # Find other language url\n","        languageURL = trageTag[0].get('href')\n","        print(f'traget URL: {languageURL}')\n","\n","        # Download page to PDF\n","        savePDF(languageURL, f'{label}_{Keyword}_{language}.pdf')\n","      else:\n","        print(f'The wikipage have no {language} language')\n","  else:\n","    print(f\"Cannot access {url}\")\n","  \n","  \n","#read CSV\n","with open(WikiKeywordsFileName) as WikiKeywordsFile:\n","    WikiKeywords = csv.reader(WikiKeywordsFile, delimiter=',')\n","    next(WikiKeywords, None)  # skip the headers\n","    i=1\n","    #Loop each Keyword\n","    for Keyword in WikiKeywords:\n","      if(len(Keyword)>0):\n","        print(f'{i}: {Keyword}')\n","        i+=1\n","        getWikiPage(Keyword[0],['th','ja'],Keyword[1])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kije3j1xUAAb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}